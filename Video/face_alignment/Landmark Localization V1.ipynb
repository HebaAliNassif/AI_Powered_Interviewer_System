{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64017267",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.color import rgb2gray\n",
    "from skimage import measure\n",
    "import cv2\n",
    "from skimage import morphology\n",
    "from skimage.morphology import disk, square, dilation, erosion\n",
    "from skimage import data\n",
    "from skimage.feature import Cascade\n",
    "from EyeCenterLocator import EyeCenterLocator\n",
    "from FaceAligner import FaceAligner\n",
    "import imutils\n",
    "from scipy import signal\n",
    "from skimage import filters\n",
    "from skimage import feature\n",
    "import skimage.io as io\n",
    "from scipy import fftpack\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.util import random_noise\n",
    "from skimage.exposure import rescale_intensity\n",
    "from PIL import Image\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "90194a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "kEyePercentTop = 25\n",
    "kEyePercentSide = 8\n",
    "kEyePercentHeight = 30\n",
    "kEyePercentWidth = 35\n",
    "\n",
    "eye_percent_height = 28\n",
    "eye_percent_width = 18\n",
    "\n",
    "mouth_percent_height = 33\n",
    "mouth_percent_width = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4d50910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastStretching(original):\n",
    "    img = original.copy()\n",
    "    xp = [0, 64, 128, 192, 255]\n",
    "    fp = [0, 16, 128, 240, 255]\n",
    "    x = np.arange(256)\n",
    "    table = np.interp(x, xp, fp).astype('uint8')\n",
    "    img = cv2.LUT(img, table)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f26960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skinDetection(sourceImage):\n",
    "    min_YCrCb = np.array([0,133,77],np.uint8)\n",
    "    max_YCrCb = np.array([255,173,127],np.uint8)\n",
    "\n",
    "    # Convert image to YCrCb\n",
    "    imageYCrCb = cv2.cvtColor(sourceImage,cv2.COLOR_RGB2YCR_CB)\n",
    "\n",
    "    # Find region with skin tone in YCrCb image\n",
    "    skinRegion = cv2.inRange(imageYCrCb,min_YCrCb,max_YCrCb)\n",
    "\n",
    "    # Do contour detection on skin region\n",
    "    contours, hierarchy = cv2.findContours(skinRegion, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Draw the contour on the source image\n",
    "    max_contour_area = -1\n",
    "    max_contour_index = -1\n",
    "    for i, c in enumerate(contours):\n",
    "        area = cv2.contourArea(c)\n",
    "        if area > max_contour_area:\n",
    "            max_contour_index = i\n",
    "            max_contour_area = area\n",
    "    sourceImage = np.zeros(sourceImage.shape).astype(sourceImage.dtype)\n",
    "    if max_contour_index > -1: \n",
    "        cv2.drawContours(sourceImage, contours, max_contour_index, (255, 255, 255), -1)\n",
    "    sourceImage = cv2.cvtColor(sourceImage,cv2.COLOR_RGB2GRAY)\n",
    "    return sourceImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b16be9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEyesCenter(face_BGR):\n",
    "    \n",
    "    eyeCenterLocator = EyeCenterLocator()\n",
    "    img_GRAY = cv2.cvtColor(face_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    eye_region_width = face_BGR.shape[0] * (kEyePercentWidth/100.0)\n",
    "    eye_region_height = face_BGR.shape[0] * (kEyePercentHeight/100.0)\n",
    "    eye_region_top = face_BGR.shape[1] * (kEyePercentTop/100.0)\n",
    "    \n",
    "    global leftEyeRegion\n",
    "    global rightEyeRegion\n",
    "    leftEyeRegion = (1,1,1,1)\n",
    "    rightEyeRegion = (1,1,1,1)\n",
    "\n",
    "    leftEyeRegion = int(face_BGR.shape[0]*(kEyePercentSide/100.0)), int(eye_region_top), int(eye_region_width), int(eye_region_height)\n",
    "    rightEyeRegion = int(face_BGR.shape[0] - eye_region_width - face_BGR.shape[0]*(kEyePercentSide/100.0)), int(eye_region_top),int(eye_region_width),int(eye_region_height)\n",
    "    \n",
    "    x1, y1, w1, h1 = (leftEyeRegion)\n",
    "    region = img_GRAY[int(y1) :int(y1) + int(h1) , int(x1) :int(x1) + int(w1)]\n",
    "    leftEyeCenter = eyeCenterLocator.locate(region)\n",
    "    \n",
    "    x2, y2, w2, h2 = (rightEyeRegion)\n",
    "    region = img_GRAY[int(y2) :int(y2) + int(h2) , int(x2) :int(x2) + int(w2)]\n",
    "    rightEyeCenter = eyeCenterLocator.locate(region)\n",
    "    \n",
    "    return (int(leftEyeCenter[1])+int(x1) , int(leftEyeCenter[0])+int(y1)), (int(rightEyeCenter[1])+int(x2), int(rightEyeCenter[0])+int(y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "90c62f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HarrisCorners(image_BGR):\n",
    "    if image_BGR.shape == (0,0) or image_BGR is None or len(image_BGR)==0:\n",
    "        return (0,0),(0,0)\n",
    "    \n",
    "    gray = cv2.cvtColor(image_BGR,cv2.COLOR_BGR2GRAY)\n",
    "    ret,threshed = cv2.threshold(gray,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    threshed = cv2.erode(threshed,None,2)\n",
    "    corner = cv2.cornerHarris(threshed, 2, 3, 0.04)\n",
    "    \n",
    "    maxLeftCorner = image_BGR.shape[1]\n",
    "    maxRieghtCorner = 0\n",
    "    \n",
    "    maxDistance = 0\n",
    "    currentDistance = maxRieghtCorner - maxLeftCorner\n",
    "    \n",
    "    maxLeftCornerPosition =(0,0)\n",
    "    maxRightCornerPosition =(0,0)\n",
    "    \n",
    "    for i in range(0, image_BGR.shape[0]):\n",
    "         for j in range(0, image_BGR.shape[1]):\n",
    "            if corner[i, j] > 0:\n",
    "                if maxLeftCorner > j:\n",
    "                    maxLeftCorner = j\n",
    "                    maxLeftCornerPosition = (j,i) \n",
    "                        \n",
    "                if maxRieghtCorner < j:\n",
    "                    maxRieghtCorner = j\n",
    "                    maxRightCornerPosition = (j,i)                   \n",
    "                    currentDistance = maxRieghtCorner-maxLeftCorner\n",
    "                    \n",
    "                if maxDistance<currentDistance:\n",
    "                    maxDistance = maxRieghtCorner-maxLeftCorner\n",
    "    return maxLeftCornerPosition, maxRightCornerPosition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fd7df57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEyeCorners(face_BGR, EyeCenter, left):\n",
    "    \n",
    "    global leftEyeCRegion\n",
    "    global rightEyeCRegion\n",
    "    \n",
    "    eye_height = int(face_BGR.shape[0]*(eye_percent_height/100.0))\n",
    "    eye_width = int(face_BGR.shape[1]*(eye_percent_width/100.0))\n",
    "    \n",
    "    top_corner = (int(EyeCenter[0]-eye_height//2), int(EyeCenter[1]-eye_width//2))\n",
    "    bootom_corner = (int(EyeCenter[0]+eye_height//2), int(EyeCenter[1]+eye_width//2))\n",
    "    \n",
    "    if(left == True):\n",
    "        leftEyeCRegion = (top_corner[0], top_corner[1], eye_height, eye_width)\n",
    "    else:\n",
    "        rightEyeCRegion = (top_corner[0], top_corner[1], eye_height, eye_width)\n",
    "        \n",
    "    eye_ROI = face_BGR[top_corner[1]:bootom_corner[1], top_corner[0]:bootom_corner[0]]\n",
    "    left_corner, right_corner = HarrisCorners(eye_ROI)\n",
    "        \n",
    "    left_corner = (left_corner[0]+top_corner[0], left_corner[1]+top_corner[1])\n",
    "    right_corner = (right_corner[0]+top_corner[0], right_corner[1]+top_corner[1])\n",
    "    \n",
    "    return left_corner, right_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e906dabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEyesCorners(face_BGR, leftEyeCenter, rightEyeCenter):\n",
    "    global leftEyeCRegion\n",
    "    global rightEyeCRegion\n",
    "    leftEyeCRegion = (1,1,1,1)\n",
    "    rightEyeCRegion = (1,1,1,1)\n",
    "    left_eye_left_corner, left_eye_right_corner = getEyeCorners(face_BGR, leftEyeCenter, True)\n",
    "    right_eye_left_corner, right_eye_right_corner = getEyeCorners(face_BGR, rightEyeCenter, False)\n",
    "    return left_eye_left_corner, left_eye_right_corner, right_eye_left_corner, right_eye_right_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5231b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMouthCorners(face_BGR):\n",
    "    global mouthRegion\n",
    "    mouthRegion = (1,1,1,1)\n",
    "    \n",
    "    # Center of lower half\n",
    "    center = (int((face_BGR.shape[0]-1-0)//2), int(face_BGR.shape[0]//2 + face_BGR.shape[0]//4))\n",
    "    #low_center = (center[0], face_BGR.shape[0]-1)\n",
    "    \n",
    "    mouth_height = int(face_BGR.shape[0]*(mouth_percent_height/100.0))\n",
    "    mouth_width = int(face_BGR.shape[1]*(mouth_percent_width/100.0))\n",
    "    \n",
    "    top_corner = (center[0]-mouth_height//2, center[1]-mouth_width//2)\n",
    "    bottom_corner = (center[0]+mouth_height//2, center[1]+mouth_width//2)\n",
    "    \n",
    "    mouthRegion = (top_corner[0], top_corner[1], mouth_height, mouth_width)\n",
    "    \n",
    "    mouth_ROI = face_BGR[top_corner[1]:bottom_corner[1], top_corner[0]:bottom_corner[0]]\n",
    "    cv2.imshow('mouth_ROI', mouth_ROI)\n",
    "    left_corner, right_corner = HarrisCorners(mouth_ROI)\n",
    "    \n",
    "    left_corner = (left_corner[0]+top_corner[0], left_corner[1]+top_corner[1])\n",
    "    right_corner = (right_corner[0]+top_corner[0],right_corner[1]+top_corner[1])\n",
    "    \n",
    "    return left_corner, right_corner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec2d30d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetMouthMap(image_RGB):\n",
    "    # transform the image to the YCbCr space\n",
    "    image_YCrCb = cv2.cvtColor(image_RGB, cv2.COLOR_RGB2YCR_CB)\n",
    "    \n",
    "    # extracting YCbCr space components\n",
    "    Y = image_YCrCb[:,:,0]\n",
    "    Cr = np.asarray(image_YCrCb[:,:,1], np.int16)\n",
    "    Cb = np.asarray(image_YCrCb[:,:,2], np.int16)\n",
    "    \n",
    "    skin = skinDetection(image_RGB)\n",
    "    \n",
    "    # calculating the MouthMap\n",
    "    n = np.count_nonzero(skin==255)\n",
    "        \n",
    "    eta = 0\n",
    "    \n",
    "    try:\n",
    "        v_1 = np.power(Cr[skin==255],2)\n",
    "        v_1 =  v_1/(np.amax(v_1)/255.0)\n",
    "\n",
    "        v_2 = np.divide(Cr[skin==255],Cb[skin==255])\n",
    "        v_2 =  v_2/(np.amax(v_2)/255.0)\n",
    "\n",
    "        eta = 0.95 * np.sum(v_1)/np.sum(v_2)\n",
    "    except ValueError:  #raised if `v_1` is empty or `v_2`\n",
    "        pass\n",
    "    \n",
    "    val_1 = np.power(Cr,2)\n",
    "    val_1 = val_1/(np.amax(val_1)/255.0)\n",
    "\n",
    "    val_2 = Cr/Cb\n",
    "    val_2 = val_2/(np.amax(val_2)/255.0)\n",
    "\n",
    "    MouthMap = val_1 * np.power(val_1 - eta * val_2, 2)\n",
    "    MouthMap = MouthMap/(np.amax(MouthMap)/255.0)\n",
    "    \n",
    "    mask = disk(10)\n",
    "    MouthMap = dilation(MouthMap, selem=mask)\n",
    "    \n",
    "    MouthMap = cv2.bitwise_and(MouthMap,  MouthMap,mask =skin)\n",
    "    \n",
    "    MouthMap = np.asarray(MouthMap, dtype='uint8')\n",
    "    \n",
    "    ret2,MouthMap = cv2.threshold(MouthMap,0,1,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    return MouthMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "84199d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MouthMapROI(image_RGB):\n",
    "    mouth_ROI = face[2*face.shape[0]//3:face.shape[0],face.shape[1]//3:2*face.shape[1]//3]\n",
    "    start_x = w//3\n",
    "    start_y = 2*h//3\n",
    "    mouth = GetMouthMap(mouth_ROI)\n",
    "    contours, hierarchy = cv2.findContours(mouth, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    l = len(contours)\n",
    "    #for contour in contours:\n",
    "    x_c = 0\n",
    "    y_c = 0\n",
    "    w_c = 0\n",
    "    h_c = 0\n",
    "    if len(contours) > 0:\n",
    "        x_c,y_c,w_c,h_c = cv2.boundingRect(contours[-1])\n",
    "        x_c += (start_x)\n",
    "        y_c += (start_y)\n",
    "    return x_c,y_c,w_c,h_c "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67023687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(img_BGR):\n",
    "    kernel = np.ones((3,3),np.float32)/9\n",
    "    img_BGR = cv2.filter2D(img_BGR,-1,kernel)\n",
    "    img_BGR = contrastStretching(img_BGR)\n",
    "    img_BGR[:,:,0] = cv2.equalizeHist(img_BGR[:,:,0])\n",
    "    img_BGR[:,:,1] = cv2.equalizeHist(img_BGR[:,:,1])\n",
    "    img_BGR[:,:,2] = cv2.equalizeHist(img_BGR[:,:,2])\n",
    "    #img_BGR = contrastStretching(img_BGR)\n",
    "    return img_BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e251e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cropImage(image, p_width, p_hieght):\n",
    "    width = image.shape[0]\n",
    "    height = image.shape[1]\n",
    "    left = int((width - width*p_width)//2)\n",
    "    top = int((height - height*p_hieght)//2)\n",
    "    right = int((width +  width*p_width)//2)\n",
    "    bottom = int((height + height*p_hieght)//2)\n",
    "    \n",
    "    return image[left:right, top:bottom]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb4c8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawLandmarks(img_BGR):\n",
    "    #img_BGR = preprocessing(img_BGR)\n",
    "    #img_BGR = cv2.resize(img_BGR, (480, 480))\n",
    "    imageAligned = img_BGR\n",
    "    img = img_BGR.copy()\n",
    "    \n",
    "    img_GRAY = cv2.cvtColor(img_BGR, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(img_GRAY)\n",
    "    fa = FaceAligner(desiredFaceWidth=256)\n",
    "    if len(faces) == 0:\n",
    "        cv2.destroyAllWindows()\n",
    "        webcam.release()\n",
    "        sys.exit()\n",
    "    for (x, y, w, h) in faces:\n",
    "        top = (x, y)\n",
    "        face_rect = (x, y, w, h)\n",
    "        \n",
    "        face = img_BGR[y :y + h , x :x + w ]\n",
    "        face = cropImage(face, 0.9, 0.8)\n",
    "        faceAligned = face \n",
    "        #face = cv2.resize(face, (256, 256))\n",
    "        \n",
    "        try:\n",
    "            (leftEyeCenter, rightEyeCenter) = getEyesCenter(face)\n",
    "            #(LEyeLCorner, LEyeRCorner, REyeLCorner, REyeRCorner) = getEyesCorners(face, leftEyeCenter, rightEyeCenter)\n",
    "            #(LMouthCorner, RMouthCorner) = getMouthCorners(face)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        imageAligned = fa.align(img_BGR, (rightEyeCenter[0]+x, rightEyeCenter[1]+y), (leftEyeCenter[0]+x, leftEyeCenter[1]+y))\n",
    "        \n",
    "        croped_face = face_cascade.detectMultiScale(cv2.cvtColor(imageAligned, cv2.COLOR_BGR2GRAY), 1.3, 4)\n",
    "        if len(croped_face)>0:\n",
    "            (xA, yA, wA, hA) = croped_face[0]\n",
    "            faceAligned = imageAligned[yA :yA + hA , xA :xA + wA]\n",
    "            \n",
    "           \n",
    "            try:\n",
    "                (leftEyeCenter, rightEyeCenter) = getEyesCenter(faceAligned)\n",
    "                (LEyeLCorner, LEyeRCorner, REyeLCorner, REyeRCorner) = getEyesCorners(faceAligned, leftEyeCenter, rightEyeCenter)\n",
    "                (LMouthCorner, RMouthCorner) = getMouthCorners(faceAligned)\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            img_BGR = cv2.circle(img_BGR, (leftEyeCenter[0]+x, leftEyeCenter[1]+y), 1, (0,0,255), -1)\n",
    "            img_BGR = cv2.circle(img_BGR, (rightEyeCenter[0]+x, rightEyeCenter[1]+y), 1, (0,0,255), -1)\n",
    "\n",
    "            faceAligned = cv2.rectangle(faceAligned, (leftEyeRegion[0], leftEyeRegion[1]), (leftEyeRegion[0] + leftEyeRegion[2], leftEyeRegion[1] + leftEyeRegion[3]), (255,0,255), 1)\n",
    "            faceAligned = cv2.rectangle(faceAligned, (rightEyeRegion[0], rightEyeRegion[1]), (rightEyeRegion[0] + rightEyeRegion[2], rightEyeRegion[1] + rightEyeRegion[3]), (255,0,255), 1)\n",
    "            \n",
    "            faceAligned = cv2.circle(faceAligned, (leftEyeCenter[0], leftEyeCenter[1]), 2, (255,0,255), -1)\n",
    "            faceAligned = cv2.circle(faceAligned, (rightEyeCenter[0], rightEyeCenter[1]), 2, (255,0,255), -1)\n",
    "\n",
    "\n",
    "            faceAligned = cv2.rectangle(faceAligned, (leftEyeCRegion[0], leftEyeCRegion[1]), (leftEyeCRegion[0] + leftEyeCRegion[2], leftEyeCRegion[1] + leftEyeCRegion[3]), (0,255,0), 1)\n",
    "\n",
    "            faceAligned = cv2.circle(faceAligned, (LEyeLCorner[0], LEyeLCorner[1]), 2, (0,255,0), -1)\n",
    "            faceAligned = cv2.circle(faceAligned, (LEyeRCorner[0], LEyeRCorner[1]), 2, (0,255,0), -1)\n",
    "\n",
    "            faceAligned = cv2.rectangle(faceAligned, (rightEyeCRegion[0], rightEyeCRegion[1]), (rightEyeCRegion[0] + rightEyeCRegion[2], rightEyeCRegion[1] + rightEyeCRegion[3]), (0,255,0), 1)\n",
    "\n",
    "            faceAligned = cv2.circle(faceAligned, (REyeLCorner[0], REyeLCorner[1]), 2, (0,255,0), -1)\n",
    "            faceAligned = cv2.circle(faceAligned, (REyeRCorner[0], REyeRCorner[1]), 2, (0,255,0), -1)\n",
    "\n",
    "            faceAligned = cv2.rectangle(faceAligned, (mouthRegion[0], mouthRegion[1]), (mouthRegion[0] + mouthRegion[2], mouthRegion[1] + mouthRegion[3]), (0,100,255), 1)\n",
    "\n",
    "            faceAligned = cv2.circle(faceAligned, (LMouthCorner[0], LMouthCorner[1]), 2, (0,100,255), -1)\n",
    "            faceAligned = cv2.circle(faceAligned, (RMouthCorner[0], RMouthCorner[1]), 2, (0,100,255), -1)\n",
    "        break\n",
    "        \n",
    "    return imageAligned, face, faceAligned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6ebece",
   "metadata": {},
   "source": [
    "# Testing using webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f77a5f36",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "webcam = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "leftEyeCenter = (0, 0)\n",
    "rightEyeCenter = (0, 0)\n",
    "leftEyeRegionStart = (0, 0)\n",
    "rightEyeRegionStart= (0, 0)\n",
    "face_rect = (0, 0, 0, 0)\n",
    "fa = FaceAligner(desiredFaceWidth=480)\n",
    "while True:\n",
    "    (_, img_BGR) = webcam.read()\n",
    "    \n",
    "    #edges = cv2.Canny(cv2.cvtColor(img_BGR,cv2.COLOR_BGR2GRAY),50,200)\n",
    "    #cv2.imshow('Egdes', edges)\n",
    "    \n",
    "    (imageAligned, face, faceAligned) = drawLandmarks(img_BGR)\n",
    "    \n",
    "    cv2.imshow('Face before 2D Alignment', face)\n",
    "    cv2.imshow('Face after 2D Alignment', faceAligned)\n",
    "    cv2.imshow('Image after 2D Alignment', imageAligned)\n",
    "    cv2.imshow('Image before 2D Alignment', img_BGR)\n",
    "    \n",
    "    key = cv2.waitKey(5)    \n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()\n",
    "webcam.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8881ba80",
   "metadata": {},
   "source": [
    "# Testing using stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4fa39f",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "haar_file = 'haarcascade_frontalface_default.xml'\n",
    "face_cascade = cv2.CascadeClassifier(haar_file)\n",
    "fa = FaceAligner(desiredFaceWidth=480)\n",
    "\n",
    "leftEyeCenter = (0, 0)\n",
    "rightEyeCenter = (0, 0)\n",
    "leftEyeRegionStart = (0, 0)\n",
    "rightEyeRegionStart= (0, 0)\n",
    "face_rect = (0, 0, 0, 0)\n",
    "\n",
    "url = \"http://192.168.137.182:8080/shot.jpg\"\n",
    "\n",
    "while True:\n",
    "    \n",
    "    img_resp = requests.get(url)\n",
    "    img_arr = np.array(bytearray(img_resp.content), dtype=np.uint8)\n",
    "    img_BGR = cv2.imdecode(img_arr, -1)\n",
    "    img_BGR = imutils.resize(img_BGR, width=480, height=960)\n",
    "    #cv2.imshow(\"Android_cam\", img)\n",
    "    \n",
    "    (imageAligned, face, faceAligned) = drawLandmarks(img_BGR)\n",
    "    \n",
    "    cv2.imshow('Face before 2D Alignment', face)\n",
    "    cv2.imshow('Face after 2D Alignment', faceAligned)\n",
    "    cv2.imshow('Image after 2D Alignment', imageAligned)\n",
    "    cv2.imshow('Image before 2D Alignment', img_BGR)\n",
    "    \n",
    "    key = cv2.waitKey(5)    \n",
    "    if key == 27:\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb195675",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
